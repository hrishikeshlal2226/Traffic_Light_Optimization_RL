{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import deque\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "import traci\n",
    "import sys\n",
    "import gym\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_traffic_lights=pd.read_csv(\"C:/Users/Pushp Raj Choudhary/OneDrive/Documents/Coding/Python/Traffic_Simulator/traffic_lights_extracted.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestep</th>\n",
       "      <th>Traffic_Light_ID</th>\n",
       "      <th>State</th>\n",
       "      <th>Phase_Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11095</th>\n",
       "      <td>3698</td>\n",
       "      <td>cluster_11502623497_1177160337</td>\n",
       "      <td>GGrrr</td>\n",
       "      <td>42.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11096</th>\n",
       "      <td>3698</td>\n",
       "      <td>cluster_664446535_8507351666</td>\n",
       "      <td>rryyy</td>\n",
       "      <td>3.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11097</th>\n",
       "      <td>3699</td>\n",
       "      <td>cluster_10279701148_11630151856_663826006</td>\n",
       "      <td>GG</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11098</th>\n",
       "      <td>3699</td>\n",
       "      <td>cluster_11502623497_1177160337</td>\n",
       "      <td>GGrrr</td>\n",
       "      <td>42.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11099</th>\n",
       "      <td>3699</td>\n",
       "      <td>cluster_664446535_8507351666</td>\n",
       "      <td>GGrrr</td>\n",
       "      <td>42.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Timestep                           Traffic_Light_ID  State  \\\n",
       "11095      3698             cluster_11502623497_1177160337  GGrrr   \n",
       "11096      3698               cluster_664446535_8507351666  rryyy   \n",
       "11097      3699  cluster_10279701148_11630151856_663826006     GG   \n",
       "11098      3699             cluster_11502623497_1177160337  GGrrr   \n",
       "11099      3699               cluster_664446535_8507351666  GGrrr   \n",
       "\n",
       "       Phase_Duration  \n",
       "11095          42.000  \n",
       "11096           3.000  \n",
       "11097           0.001  \n",
       "11098          42.000  \n",
       "11099          42.000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_traffic_lights.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestep</th>\n",
       "      <th>Traffic_Light_ID</th>\n",
       "      <th>State</th>\n",
       "      <th>Phase_Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11093</th>\n",
       "      <td>3697</td>\n",
       "      <td>cluster_664446535_8507351666</td>\n",
       "      <td>rryyy</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11095</th>\n",
       "      <td>3698</td>\n",
       "      <td>cluster_11502623497_1177160337</td>\n",
       "      <td>GGrrr</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11096</th>\n",
       "      <td>3698</td>\n",
       "      <td>cluster_664446535_8507351666</td>\n",
       "      <td>rryyy</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11098</th>\n",
       "      <td>3699</td>\n",
       "      <td>cluster_11502623497_1177160337</td>\n",
       "      <td>GGrrr</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11099</th>\n",
       "      <td>3699</td>\n",
       "      <td>cluster_664446535_8507351666</td>\n",
       "      <td>GGrrr</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Timestep                Traffic_Light_ID  State  Phase_Duration\n",
       "11093      3697    cluster_664446535_8507351666  rryyy             3.0\n",
       "11095      3698  cluster_11502623497_1177160337  GGrrr            42.0\n",
       "11096      3698    cluster_664446535_8507351666  rryyy             3.0\n",
       "11098      3699  cluster_11502623497_1177160337  GGrrr            42.0\n",
       "11099      3699    cluster_664446535_8507351666  GGrrr            42.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_traffic_lights = df_traffic_lights[df_traffic_lights[\"Traffic_Light_ID\"] != \"cluster_10279701148_11630151856_663826006\"]   # Remove this traffic light as it is not present (or giving false sense of presence [giving green state always]) in the simulation\n",
    "df_traffic_lights.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_traffic_lights['Traffic_Light_1_2'] = df_traffic_lights['State'].apply(lambda x: x[:2])  # First two traffic light states (Same path but diff. direction)\n",
    "df_traffic_lights['Traffic_Light_3_4'] = df_traffic_lights['State'].apply(lambda x: x[2:4])  # Second two traffic light states (Same path but diff. direction)\n",
    "df_traffic_lights['Zebra_Crossing_Light'] = df_traffic_lights['State'].apply(lambda x: x[4])  # Zebra crossing state (Same path but diff. direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_traffic_lights.tail(5)\n",
    "df_traffic_lights.to_csv(\"C:/Users/Pushp Raj Choudhary/Documents/Coding/Python/Traffic_Simulator/traffic_lights_extracted_with_differentiation.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestep</th>\n",
       "      <th>Vehicle_ID</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Lane_ID</th>\n",
       "      <th>Edge_ID</th>\n",
       "      <th>X_Position</th>\n",
       "      <th>Y_Position</th>\n",
       "      <th>Acceleration</th>\n",
       "      <th>Angle</th>\n",
       "      <th>Depart_Time</th>\n",
       "      <th>...</th>\n",
       "      <th>Waiting_Time</th>\n",
       "      <th>Time_Loss</th>\n",
       "      <th>Distance_Traveled</th>\n",
       "      <th>CO2_Emission</th>\n",
       "      <th>Fuel_Consumption</th>\n",
       "      <th>NOx_Emission</th>\n",
       "      <th>PMx_Emission</th>\n",
       "      <th>Traffic_Light_ID</th>\n",
       "      <th>State</th>\n",
       "      <th>Phase_Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>769473</th>\n",
       "      <td>3739.0</td>\n",
       "      <td>veh409</td>\n",
       "      <td>5.74</td>\n",
       "      <td>:10943498141_3_0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>241.80</td>\n",
       "      <td>220.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.93</td>\n",
       "      <td>3577.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.01</td>\n",
       "      <td>1902.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769474</th>\n",
       "      <td>3740.0</td>\n",
       "      <td>veh409</td>\n",
       "      <td>5.64</td>\n",
       "      <td>:10943498141_3_0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>246.05</td>\n",
       "      <td>223.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.33</td>\n",
       "      <td>3577.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.01</td>\n",
       "      <td>1902.73</td>\n",
       "      <td>1988.18</td>\n",
       "      <td>634.17</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769475</th>\n",
       "      <td>3741.0</td>\n",
       "      <td>veh409</td>\n",
       "      <td>6.56</td>\n",
       "      <td>-101966385#4_0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>248.18</td>\n",
       "      <td>229.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.62</td>\n",
       "      <td>3577.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.01</td>\n",
       "      <td>1902.73</td>\n",
       "      <td>3687.26</td>\n",
       "      <td>1176.08</td>\n",
       "      <td>1.53</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769476</th>\n",
       "      <td>3742.0</td>\n",
       "      <td>veh409</td>\n",
       "      <td>8.45</td>\n",
       "      <td>-101966385#4_0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>250.74</td>\n",
       "      <td>237.42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.62</td>\n",
       "      <td>3577.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.01</td>\n",
       "      <td>1902.73</td>\n",
       "      <td>6262.04</td>\n",
       "      <td>1997.30</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769477</th>\n",
       "      <td>3743.0</td>\n",
       "      <td>veh409</td>\n",
       "      <td>10.55</td>\n",
       "      <td>-101966385#4_0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>253.93</td>\n",
       "      <td>247.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.62</td>\n",
       "      <td>3577.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.01</td>\n",
       "      <td>1902.73</td>\n",
       "      <td>7905.93</td>\n",
       "      <td>2521.61</td>\n",
       "      <td>3.41</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Timestep Vehicle_ID  Speed           Lane_ID  Edge_ID  X_Position  \\\n",
       "769473    3739.0     veh409   5.74  :10943498141_3_0  Unknown      241.80   \n",
       "769474    3740.0     veh409   5.64  :10943498141_3_0  Unknown      246.05   \n",
       "769475    3741.0     veh409   6.56    -101966385#4_0  Unknown      248.18   \n",
       "769476    3742.0     veh409   8.45    -101966385#4_0  Unknown      250.74   \n",
       "769477    3743.0     veh409  10.55    -101966385#4_0  Unknown      253.93   \n",
       "\n",
       "        Y_Position  Acceleration   Angle  Depart_Time  ...  Waiting_Time  \\\n",
       "769473      220.00           0.0  101.93       3577.0  ...           0.0   \n",
       "769474      223.16           0.0   50.33       3577.0  ...           0.0   \n",
       "769475      229.36           0.0   17.62       3577.0  ...           0.0   \n",
       "769476      237.42           0.0   17.62       3577.0  ...           0.0   \n",
       "769477      247.48           0.0   17.62       3577.0  ...           0.0   \n",
       "\n",
       "        Time_Loss  Distance_Traveled  CO2_Emission  Fuel_Consumption  \\\n",
       "769473      35.01            1902.73          0.00              0.00   \n",
       "769474      35.01            1902.73       1988.18            634.17   \n",
       "769475      35.01            1902.73       3687.26           1176.08   \n",
       "769476      35.01            1902.73       6262.04           1997.30   \n",
       "769477      35.01            1902.73       7905.93           2521.61   \n",
       "\n",
       "        NOx_Emission  PMx_Emission  Traffic_Light_ID  State Phase_Duration  \n",
       "769473          0.00          0.00                 0      0            0.0  \n",
       "769474          0.75          0.02                 0      0            0.0  \n",
       "769475          1.53          0.06                 0      0            0.0  \n",
       "769476          2.69          0.12                 0      0            0.0  \n",
       "769477          3.41          0.16                 0      0            0.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined = pd.read_csv(\"C:/Users/Pushp Raj Choudhary/Documents/Coding/Python/Traffic_Simulator/combined_sumo_data2.csv\")\n",
    "df_combined.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Last few rows after 3700 timet steps are not recorded for the traffic light so we will use the 3700 timesteps for training and execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestep</th>\n",
       "      <th>Vehicle_ID</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Lane_ID</th>\n",
       "      <th>Edge_ID</th>\n",
       "      <th>X_Position</th>\n",
       "      <th>Y_Position</th>\n",
       "      <th>Acceleration</th>\n",
       "      <th>Angle</th>\n",
       "      <th>Depart_Time</th>\n",
       "      <th>...</th>\n",
       "      <th>Waiting_Time</th>\n",
       "      <th>Time_Loss</th>\n",
       "      <th>Distance_Traveled</th>\n",
       "      <th>CO2_Emission</th>\n",
       "      <th>Fuel_Consumption</th>\n",
       "      <th>NOx_Emission</th>\n",
       "      <th>PMx_Emission</th>\n",
       "      <th>Traffic_Light_ID</th>\n",
       "      <th>State</th>\n",
       "      <th>Phase_Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>769429</th>\n",
       "      <td>3698.0</td>\n",
       "      <td>veh411</td>\n",
       "      <td>11.10</td>\n",
       "      <td>103050330#0_0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>893.40</td>\n",
       "      <td>505.79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>109.04</td>\n",
       "      <td>3595.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.16</td>\n",
       "      <td>1268.25</td>\n",
       "      <td>5908.83</td>\n",
       "      <td>1884.64</td>\n",
       "      <td>2.46</td>\n",
       "      <td>0.11</td>\n",
       "      <td>cluster_664446535_8507351666</td>\n",
       "      <td>rryyy</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769430</th>\n",
       "      <td>3699.0</td>\n",
       "      <td>veh409</td>\n",
       "      <td>22.40</td>\n",
       "      <td>:1190100061_1_0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>363.67</td>\n",
       "      <td>406.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>287.97</td>\n",
       "      <td>3577.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.01</td>\n",
       "      <td>1902.73</td>\n",
       "      <td>5031.86</td>\n",
       "      <td>1604.93</td>\n",
       "      <td>1.77</td>\n",
       "      <td>0.08</td>\n",
       "      <td>cluster_11502623497_1177160337</td>\n",
       "      <td>GGrrr</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769431</th>\n",
       "      <td>3699.0</td>\n",
       "      <td>veh409</td>\n",
       "      <td>22.40</td>\n",
       "      <td>:1190100061_1_0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>363.67</td>\n",
       "      <td>406.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>287.97</td>\n",
       "      <td>3577.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.01</td>\n",
       "      <td>1902.73</td>\n",
       "      <td>5031.86</td>\n",
       "      <td>1604.93</td>\n",
       "      <td>1.77</td>\n",
       "      <td>0.08</td>\n",
       "      <td>cluster_664446535_8507351666</td>\n",
       "      <td>GGrrr</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769432</th>\n",
       "      <td>3699.0</td>\n",
       "      <td>veh411</td>\n",
       "      <td>13.57</td>\n",
       "      <td>103050330#0_0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>906.23</td>\n",
       "      <td>501.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>109.04</td>\n",
       "      <td>3595.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.16</td>\n",
       "      <td>1268.25</td>\n",
       "      <td>11054.47</td>\n",
       "      <td>3525.82</td>\n",
       "      <td>4.82</td>\n",
       "      <td>0.24</td>\n",
       "      <td>cluster_11502623497_1177160337</td>\n",
       "      <td>GGrrr</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769433</th>\n",
       "      <td>3699.0</td>\n",
       "      <td>veh411</td>\n",
       "      <td>13.57</td>\n",
       "      <td>103050330#0_0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>906.23</td>\n",
       "      <td>501.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>109.04</td>\n",
       "      <td>3595.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.16</td>\n",
       "      <td>1268.25</td>\n",
       "      <td>11054.47</td>\n",
       "      <td>3525.82</td>\n",
       "      <td>4.82</td>\n",
       "      <td>0.24</td>\n",
       "      <td>cluster_664446535_8507351666</td>\n",
       "      <td>GGrrr</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Timestep Vehicle_ID  Speed          Lane_ID  Edge_ID  X_Position  \\\n",
       "769429    3698.0     veh411  11.10    103050330#0_0  Unknown      893.40   \n",
       "769430    3699.0     veh409  22.40  :1190100061_1_0  Unknown      363.67   \n",
       "769431    3699.0     veh409  22.40  :1190100061_1_0  Unknown      363.67   \n",
       "769432    3699.0     veh411  13.57    103050330#0_0  Unknown      906.23   \n",
       "769433    3699.0     veh411  13.57    103050330#0_0  Unknown      906.23   \n",
       "\n",
       "        Y_Position  Acceleration   Angle  Depart_Time  ...  Waiting_Time  \\\n",
       "769429      505.79           0.0  109.04       3595.0  ...           1.0   \n",
       "769430      406.63           0.0  287.97       3577.0  ...           0.0   \n",
       "769431      406.63           0.0  287.97       3577.0  ...           0.0   \n",
       "769432      501.36           0.0  109.04       3595.0  ...           1.0   \n",
       "769433      501.36           0.0  109.04       3595.0  ...           1.0   \n",
       "\n",
       "        Time_Loss  Distance_Traveled  CO2_Emission  Fuel_Consumption  \\\n",
       "769429      32.16            1268.25       5908.83           1884.64   \n",
       "769430      35.01            1902.73       5031.86           1604.93   \n",
       "769431      35.01            1902.73       5031.86           1604.93   \n",
       "769432      32.16            1268.25      11054.47           3525.82   \n",
       "769433      32.16            1268.25      11054.47           3525.82   \n",
       "\n",
       "        NOx_Emission  PMx_Emission                Traffic_Light_ID  State  \\\n",
       "769429          2.46          0.11    cluster_664446535_8507351666  rryyy   \n",
       "769430          1.77          0.08  cluster_11502623497_1177160337  GGrrr   \n",
       "769431          1.77          0.08    cluster_664446535_8507351666  GGrrr   \n",
       "769432          4.82          0.24  cluster_11502623497_1177160337  GGrrr   \n",
       "769433          4.82          0.24    cluster_664446535_8507351666  GGrrr   \n",
       "\n",
       "       Phase_Duration  \n",
       "769429            3.0  \n",
       "769430           42.0  \n",
       "769431           42.0  \n",
       "769432           42.0  \n",
       "769433           42.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined = df_combined[df_combined['Timestep'] <= 3699]\n",
    "df_combined.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestep</th>\n",
       "      <th>Vehicle_ID</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Lane_ID</th>\n",
       "      <th>Edge_ID</th>\n",
       "      <th>X_Position</th>\n",
       "      <th>Y_Position</th>\n",
       "      <th>Acceleration</th>\n",
       "      <th>Angle</th>\n",
       "      <th>Depart_Time</th>\n",
       "      <th>...</th>\n",
       "      <th>CO2_Emission</th>\n",
       "      <th>Fuel_Consumption</th>\n",
       "      <th>NOx_Emission</th>\n",
       "      <th>PMx_Emission</th>\n",
       "      <th>Traffic_Light_ID</th>\n",
       "      <th>State</th>\n",
       "      <th>Phase_Duration</th>\n",
       "      <th>Traffic_Light_1_2</th>\n",
       "      <th>Traffic_Light_3_4</th>\n",
       "      <th>Zebra_Crossing_Light</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1538863</th>\n",
       "      <td>3699.0</td>\n",
       "      <td>veh409</td>\n",
       "      <td>22.40</td>\n",
       "      <td>:1190100061_1_0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>363.67</td>\n",
       "      <td>406.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>287.97</td>\n",
       "      <td>3577.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5031.86</td>\n",
       "      <td>1604.93</td>\n",
       "      <td>1.77</td>\n",
       "      <td>0.08</td>\n",
       "      <td>cluster_664446535_8507351666</td>\n",
       "      <td>GGrrr</td>\n",
       "      <td>42.0</td>\n",
       "      <td>GG</td>\n",
       "      <td>rr</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538864</th>\n",
       "      <td>3699.0</td>\n",
       "      <td>veh411</td>\n",
       "      <td>13.57</td>\n",
       "      <td>103050330#0_0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>906.23</td>\n",
       "      <td>501.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>109.04</td>\n",
       "      <td>3595.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11054.47</td>\n",
       "      <td>3525.82</td>\n",
       "      <td>4.82</td>\n",
       "      <td>0.24</td>\n",
       "      <td>cluster_11502623497_1177160337</td>\n",
       "      <td>GGrrr</td>\n",
       "      <td>42.0</td>\n",
       "      <td>GG</td>\n",
       "      <td>rr</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538865</th>\n",
       "      <td>3699.0</td>\n",
       "      <td>veh411</td>\n",
       "      <td>13.57</td>\n",
       "      <td>103050330#0_0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>906.23</td>\n",
       "      <td>501.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>109.04</td>\n",
       "      <td>3595.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11054.47</td>\n",
       "      <td>3525.82</td>\n",
       "      <td>4.82</td>\n",
       "      <td>0.24</td>\n",
       "      <td>cluster_664446535_8507351666</td>\n",
       "      <td>GGrrr</td>\n",
       "      <td>42.0</td>\n",
       "      <td>GG</td>\n",
       "      <td>rr</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538866</th>\n",
       "      <td>3699.0</td>\n",
       "      <td>veh411</td>\n",
       "      <td>13.57</td>\n",
       "      <td>103050330#0_0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>906.23</td>\n",
       "      <td>501.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>109.04</td>\n",
       "      <td>3595.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11054.47</td>\n",
       "      <td>3525.82</td>\n",
       "      <td>4.82</td>\n",
       "      <td>0.24</td>\n",
       "      <td>cluster_11502623497_1177160337</td>\n",
       "      <td>GGrrr</td>\n",
       "      <td>42.0</td>\n",
       "      <td>GG</td>\n",
       "      <td>rr</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538867</th>\n",
       "      <td>3699.0</td>\n",
       "      <td>veh411</td>\n",
       "      <td>13.57</td>\n",
       "      <td>103050330#0_0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>906.23</td>\n",
       "      <td>501.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>109.04</td>\n",
       "      <td>3595.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11054.47</td>\n",
       "      <td>3525.82</td>\n",
       "      <td>4.82</td>\n",
       "      <td>0.24</td>\n",
       "      <td>cluster_664446535_8507351666</td>\n",
       "      <td>GGrrr</td>\n",
       "      <td>42.0</td>\n",
       "      <td>GG</td>\n",
       "      <td>rr</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Timestep Vehicle_ID  Speed          Lane_ID  Edge_ID  X_Position  \\\n",
       "1538863    3699.0     veh409  22.40  :1190100061_1_0  Unknown      363.67   \n",
       "1538864    3699.0     veh411  13.57    103050330#0_0  Unknown      906.23   \n",
       "1538865    3699.0     veh411  13.57    103050330#0_0  Unknown      906.23   \n",
       "1538866    3699.0     veh411  13.57    103050330#0_0  Unknown      906.23   \n",
       "1538867    3699.0     veh411  13.57    103050330#0_0  Unknown      906.23   \n",
       "\n",
       "         Y_Position  Acceleration   Angle  Depart_Time  ...  CO2_Emission  \\\n",
       "1538863      406.63           0.0  287.97       3577.0  ...       5031.86   \n",
       "1538864      501.36           0.0  109.04       3595.0  ...      11054.47   \n",
       "1538865      501.36           0.0  109.04       3595.0  ...      11054.47   \n",
       "1538866      501.36           0.0  109.04       3595.0  ...      11054.47   \n",
       "1538867      501.36           0.0  109.04       3595.0  ...      11054.47   \n",
       "\n",
       "         Fuel_Consumption  NOx_Emission  PMx_Emission  \\\n",
       "1538863           1604.93          1.77          0.08   \n",
       "1538864           3525.82          4.82          0.24   \n",
       "1538865           3525.82          4.82          0.24   \n",
       "1538866           3525.82          4.82          0.24   \n",
       "1538867           3525.82          4.82          0.24   \n",
       "\n",
       "                       Traffic_Light_ID  State  Phase_Duration  \\\n",
       "1538863    cluster_664446535_8507351666  GGrrr            42.0   \n",
       "1538864  cluster_11502623497_1177160337  GGrrr            42.0   \n",
       "1538865    cluster_664446535_8507351666  GGrrr            42.0   \n",
       "1538866  cluster_11502623497_1177160337  GGrrr            42.0   \n",
       "1538867    cluster_664446535_8507351666  GGrrr            42.0   \n",
       "\n",
       "         Traffic_Light_1_2  Traffic_Light_3_4 Zebra_Crossing_Light  \n",
       "1538863                 GG                 rr                    r  \n",
       "1538864                 GG                 rr                    r  \n",
       "1538865                 GG                 rr                    r  \n",
       "1538866                 GG                 rr                    r  \n",
       "1538867                 GG                 rr                    r  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined=df_combined.drop(columns=['Traffic_Light_ID', 'State', 'Phase_Duration'])\n",
    "df_combined = pd.merge(df_combined, df_traffic_lights, on=['Timestep'], how='left')\n",
    "df_combined.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories for checkpoints and results\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "os.makedirs(\"logs\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    try:\n",
    "        print(\"Loading combined data...\")\n",
    "        combined_data = df_combined.copy()  # Use the modified DataFrame\n",
    "        print(f\"Data loaded successfully with {len(combined_data)} records\")\n",
    "        # Save a backup of the original data\n",
    "        combined_data.to_csv(\"checkpoints/original_data_backup.csv\", index=False)\n",
    "        return combined_data\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_sumo(sumocfg_path):\n",
    "    try:\n",
    "        print(\"Initializing SUMO environment...\")\n",
    "        sumo_cmd = [\"sumo\", \"-c\", sumocfg_path, \"--start\"]\n",
    "        traci.start(sumo_cmd)\n",
    "        print(\"SUMO environment initialized successfully\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing SUMO: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State representation\n",
    "def get_state(traffic_data, current_timestep):\n",
    "    \"\"\"Extract state features from traffic data at the current timestep\"\"\"\n",
    "    try:\n",
    "        # Filter data for current timestep\n",
    "        current_data = traffic_data[traffic_data[\"Timestep\"] == current_timestep]\n",
    "        \n",
    "        if current_data.empty:\n",
    "            print(f\"No data found for timestep {current_timestep}\")\n",
    "            return None\n",
    "        \n",
    "        # Load lane groups mapping if not provided\n",
    "        if lane_groups_mapping is None:\n",
    "            lane_groups_mapping = pd.read_csv(\"C:/Users/Pushp Raj Choudhary/Documents/Coding/Python/Traffic_Simulator/lane_groups.csv\")\n",
    "            # Create a dictionary mapping lane IDs to their group\n",
    "            lane_to_group = {}\n",
    "            for col in lane_groups_mapping.columns:\n",
    "                group = col\n",
    "                for lane in lane_groups_mapping[col].dropna().values:\n",
    "                    lane_to_group[lane] = group\n",
    "        \n",
    "        # Create Lane_Group using the mapping\n",
    "        current_data.loc[:, \"Lane_Group\"] = current_data[\"Lane_ID\"].map(lane_to_group)\n",
    "        # Fill any unmapped lanes with \"Other\"\n",
    "        current_data.loc[:, \"Lane_Group\"] = current_data[\"Lane_Group\"].fillna(\"Other\")\n",
    "        \n",
    "        # Extract vehicle density per lane group\n",
    "        lane_density = current_data.groupby(\"Lane_Group\")[\"Vehicle_ID\"].count().to_dict()\n",
    "        \n",
    "        # Extract average speed per lane group\n",
    "        avg_speed = current_data.groupby(\"Lane_Group\")[\"Speed\"].mean().to_dict()\n",
    "        \n",
    "        # Extract waiting time\n",
    "        avg_waiting_time = current_data[\"Waiting_Time\"].mean()\n",
    "        \n",
    "        # Extract traffic light states\n",
    "        tl_states = current_data[[\"Traffic_Light_1_2\", \"Traffic_Light_3_4\", \"Zebra_Crossing_Light\"]].drop_duplicates().values.tolist()\n",
    "        \n",
    "        # Combine features into state vector\n",
    "        state_features = []\n",
    "        \n",
    "        # Add lane density features\n",
    "        for lane_group in sorted(lane_density.keys()):\n",
    "            state_features.append(lane_density.get(lane_group, 0))\n",
    "        \n",
    "        # Add speed features\n",
    "        for lane_group in sorted(avg_speed.keys()):\n",
    "            state_features.append(avg_speed.get(lane_group, 0))\n",
    "        \n",
    "        # Add waiting time\n",
    "        state_features.append(avg_waiting_time)\n",
    "        \n",
    "        # Add traffic light features (one-hot encode the traffic light states)\n",
    "        for tl in tl_states:\n",
    "            # Encode Traffic_Light_1_2 (one-hot encoding for each state)\n",
    "            if 'GG' in tl[0]:  # Green state\n",
    "                state_features.extend([1, 0, 0])\n",
    "            elif 'yy' in tl[0]:  # Yellow state\n",
    "                state_features.extend([0, 1, 0])\n",
    "            else:  # Red state\n",
    "                state_features.extend([0, 0, 1])\n",
    "            \n",
    "            # Encode Traffic_Light_3_4 (one-hot encoding for each state)\n",
    "            if 'GG' in tl[1]:  # Green state\n",
    "                state_features.extend([1, 0, 0])\n",
    "            elif 'yy' in tl[1]:  # Yellow state\n",
    "                state_features.extend([0, 1, 0])\n",
    "            else:  # Red state\n",
    "                state_features.extend([0, 0, 1])\n",
    "            \n",
    "            # Encode Zebra_Crossing_Light (one-hot encoding for each state)\n",
    "            if 'G' or 'g' in tl[2]:  # Green state\n",
    "                state_features.extend([1, 0, 0])\n",
    "            elif 'y' in tl[2]:  # Yellow state\n",
    "                state_features.extend([0, 1, 0])\n",
    "            else:  # Red state\n",
    "                state_features.extend([0, 0, 1])\n",
    "        \n",
    "        # Save state representation for debugging\n",
    "        with open(f\"checkpoints/state_representation_{current_timestep}.pkl\", \"wb\") as f:\n",
    "            pickle.dump(state_features, f)            \n",
    "        return np.array(state_features, dtype=np.float32)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in get_state: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Action Implementation in SUMO using TraCI API\n",
    "def take_action(action, traffic_light_ids):\n",
    "    \"\"\"\n",
    "    Implement the selected action in the SUMO environment\n",
    "    \n",
    "    Actions:\n",
    "    0: Maintain current phase\n",
    "    1: Switch state of Traffic_Light_1_2\n",
    "    2: Switch state of Traffic_Light_3_4\n",
    "    3: Switch Zebra_Crossing_Light\n",
    "    4: Extend green phase for Traffic_Light_1_2\n",
    "    5: Reduce green phase for Traffic_Light_1_2\n",
    "    6: Increase yellow phase for Traffic_Light_1_2\n",
    "    7: Decrease yellow phase for Traffic_Light_1_2\n",
    "    \"\"\"\n",
    "    try:\n",
    "        action_log = {}\n",
    "        for tl_id in traffic_light_ids:\n",
    "            prev_phase = traci.trafficlight.getPhase(tl_id)\n",
    "            prev_duration = traci.trafficlight.getPhaseDuration(tl_id)\n",
    "            \n",
    "            if action == 0:\n",
    "                # Action 0: Maintain current phase\n",
    "                pass\n",
    "            elif action == 1:\n",
    "                # Action 1: Switch state of Traffic_Light_1_2\n",
    "                next_phase = (prev_phase + 1) % traci.trafficlight.getPhaseCount(tl_id)\n",
    "                traci.trafficlight.setPhase(tl_id, next_phase)\n",
    "            elif action == 2:\n",
    "                # Action 2: Switch state of Traffic_Light_3_4\n",
    "                next_phase = (prev_phase + 1) % traci.trafficlight.getPhaseCount(tl_id)\n",
    "                traci.trafficlight.setPhase(tl_id, next_phase)\n",
    "            elif action == 3:\n",
    "                # Action 3: Switch Zebra Crossing Light\n",
    "                next_phase = (prev_phase + 1) % traci.trafficlight.getPhaseCount(tl_id)\n",
    "                traci.trafficlight.setPhase(tl_id, next_phase)\n",
    "            elif action == 4:\n",
    "                # Action 4: Extend green phase for Traffic_Light_1_2\n",
    "                current_duration = traci.trafficlight.getPhaseDuration(tl_id)\n",
    "                traci.trafficlight.setPhaseDuration(tl_id, current_duration + 5)\n",
    "            elif action == 5:\n",
    "                # Action 5: Reduce green phase for Traffic_Light_1_2\n",
    "                current_duration = traci.trafficlight.getPhaseDuration(tl_id)\n",
    "                if current_duration > 10:\n",
    "                    traci.trafficlight.setPhaseDuration(tl_id, current_duration - 5)\n",
    "            elif action == 6:\n",
    "                # Action 6: Increase yellow phase for Traffic_Light_1_2\n",
    "                current_duration = traci.trafficlight.getPhaseDuration(tl_id)\n",
    "                traci.trafficlight.setPhaseDuration(tl_id, current_duration + 5)\n",
    "            elif action == 7:\n",
    "                # Action 7: Decrease yellow phase for Traffic_Light_1_2\n",
    "                current_duration = traci.trafficlight.getPhaseDuration(tl_id)\n",
    "                if current_duration > 5:\n",
    "                    traci.trafficlight.setPhaseDuration(tl_id, current_duration - 5)\n",
    "            \n",
    "            # Log the action for debugging\n",
    "            action_log[tl_id] = {\n",
    "                \"prev_phase\": prev_phase,\n",
    "                \"prev_duration\": prev_duration,\n",
    "                \"new_phase\": traci.trafficlight.getPhase(tl_id),\n",
    "                \"new_duration\": traci.trafficlight.getPhaseDuration(tl_id),\n",
    "                \"action_taken\": action\n",
    "            }\n",
    "        \n",
    "        # Save action log for debugging\n",
    "        with open(f\"logs/action_log_{time.time()}.json\", \"w\") as f:\n",
    "            json.dump(action_log, f)         \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error in take_action: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, state_size, action_size):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, action_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "    \n",
    "    def save(self, path):\n",
    "        torch.save(self.state_dict(), path)\n",
    "        \n",
    "    def load(self, path):\n",
    "        self.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "    \n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.buffer, batch_size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "    \n",
    "    def save(self, path):\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump(self.buffer, f)\n",
    "    \n",
    "    def load(self, path):\n",
    "        with open(path, 'rb') as f:\n",
    "            self.buffer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size, learning_rate=0.001, gamma=0.95, \n",
    "                 epsilon=1.0, epsilon_decay=0.995, epsilon_min=0.01, \n",
    "                 buffer_size=10000, batch_size=32):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.gamma = gamma  # discount factor\n",
    "        self.epsilon = epsilon  # exploration rate\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # Initialize Q-networks (online and target)\n",
    "        self.q_network = DQN(state_size, action_size)\n",
    "        self.target_network = DQN(state_size, action_size)\n",
    "        self.target_network.load_state_dict(self.q_network.state_dict())\n",
    "        \n",
    "        # Initialize optimizer\n",
    "        self.optimizer = optim.Adam(self.q_network.parameters(), lr=learning_rate)\n",
    "        \n",
    "        # Initialize replay buffer\n",
    "        self.memory = ReplayBuffer(buffer_size)\n",
    "        \n",
    "        # Initialize loss function\n",
    "        self.criterion = nn.MSELoss()\n",
    "        \n",
    "        # Training metrics\n",
    "        self.loss_history = []\n",
    "        self.reward_history = []\n",
    "        self.epsilon_history = []\n",
    "    \n",
    "    def update_target_network(self):\n",
    "        \"\"\"Update target network with weights from online network\"\"\"\n",
    "        self.target_network.load_state_dict(self.q_network.state_dict())\n",
    "    \n",
    "    def select_action(self, state):\n",
    "        \"\"\"Select action using epsilon-greedy policy\"\"\"\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        \n",
    "        state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            q_values = self.q_network(state_tensor)\n",
    "        return q_values.argmax().item()\n",
    "    \n",
    "    def store_experience(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Store experience in replay buffer\"\"\"\n",
    "        self.memory.add(state, action, reward, next_state, done)\n",
    "    \n",
    "    def train(self):\n",
    "        \"\"\"Train the agent using experiences from replay buffer\"\"\"\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            return 0  # Return 0 loss if not enough samples\n",
    "        \n",
    "        # Sample batch from replay buffer\n",
    "        batch = self.memory.sample(self.batch_size)\n",
    "        states, actions, rewards, next_states, dones = zip(*batch)\n",
    "        \n",
    "        # Convert to tensors\n",
    "        states = torch.FloatTensor(np.array(states))\n",
    "        actions = torch.LongTensor(actions).unsqueeze(1)\n",
    "        rewards = torch.FloatTensor(rewards)\n",
    "        next_states = torch.FloatTensor(np.array(next_states))\n",
    "        dones = torch.FloatTensor(dones)\n",
    "        \n",
    "        # Compute current Q values\n",
    "        current_q_values = self.q_network(states).gather(1, actions).squeeze()\n",
    "        \n",
    "        # Compute target Q values\n",
    "        with torch.no_grad():\n",
    "            max_next_q_values = self.target_network(next_states).max(1)[0]\n",
    "            target_q_values = rewards + (1 - dones) * self.gamma * max_next_q_values\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = self.criterion(current_q_values, target_q_values)\n",
    "        \n",
    "        # Update online network\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        # Record loss\n",
    "        self.loss_history.append(loss.item())\n",
    "        \n",
    "        # Decay epsilon\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "            self.epsilon_history.append(self.epsilon)\n",
    "        \n",
    "        return loss.item()\n",
    "    \n",
    "    def save(self, episode):\n",
    "        \"\"\"Save agent state\"\"\"\n",
    "        checkpoint = {\n",
    "            'q_network_state': self.q_network.state_dict(),\n",
    "            'target_network_state': self.target_network.state_dict(),\n",
    "            'optimizer_state': self.optimizer.state_dict(),\n",
    "            'epsilon': self.epsilon,\n",
    "            'loss_history': self.loss_history,\n",
    "            'reward_history': self.reward_history,\n",
    "            'epsilon_history': self.epsilon_history\n",
    "        }\n",
    "        torch.save(checkpoint, f\"checkpoints/agent_checkpoint_ep{episode}.pt\")\n",
    "        self.memory.save(f\"checkpoints/replay_buffer_ep{episode}.pkl\")\n",
    "        \n",
    "        # Save metrics separately for easy access\n",
    "        np.save(f\"results/loss_history_ep{episode}.npy\", np.array(self.loss_history))\n",
    "        np.save(f\"results/reward_history_ep{episode}.npy\", np.array(self.reward_history))\n",
    "        np.save(f\"results/epsilon_history_ep{episode}.npy\", np.array(self.epsilon_history))\n",
    "    \n",
    "    def load(self, episode):\n",
    "        \"\"\"Load agent state\"\"\"\n",
    "        try:\n",
    "            checkpoint = torch.load(f\"checkpoints/agent_checkpoint_ep{episode}.pt\")\n",
    "            self.q_network.load_state_dict(checkpoint['q_network_state'])\n",
    "            self.target_network.load_state_dict(checkpoint['target_network_state'])\n",
    "            self.optimizer.load_state_dict(checkpoint['optimizer_state'])\n",
    "            self.epsilon = checkpoint['epsilon']\n",
    "            self.loss_history = checkpoint['loss_history']\n",
    "            self.reward_history = checkpoint['reward_history']\n",
    "            self.epsilon_history = checkpoint['epsilon_history']\n",
    "            \n",
    "            # Load replay buffer\n",
    "            self.memory.load(f\"checkpoints/replay_buffer_ep{episode}.pkl\")\n",
    "            \n",
    "            print(f\"Successfully loaded checkpoint from episode {episode}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading checkpoint: {e}\")\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_reward(current_data, previous_data, action_taken):\n",
    "    \"\"\"Calculate reward based on traffic metrics\"\"\"\n",
    "    try:\n",
    "        # Initialize reward components dictionary for logging\n",
    "        reward_components = {}\n",
    "        \n",
    "        # Calculate average waiting time difference\n",
    "        current_waiting = current_data[\"Waiting_Time\"].mean()\n",
    "        previous_waiting = previous_data[\"Waiting_Time\"].mean() if previous_data is not None else 0\n",
    "        waiting_diff = previous_waiting - current_waiting\n",
    "        reward_components[\"waiting_diff\"] = waiting_diff\n",
    "        \n",
    "        # Calculate average speed difference\n",
    "        current_speed = current_data[\"Speed\"].mean()\n",
    "        previous_speed = previous_data[\"Speed\"].mean() if previous_data is not None else 0\n",
    "        speed_diff = current_speed - previous_speed\n",
    "        reward_components[\"speed_diff\"] = speed_diff\n",
    "        \n",
    "        # Calculate emissions difference\n",
    "        current_emissions = current_data[\"CO2_Emission\"].mean()\n",
    "        previous_emissions = previous_data[\"CO2_Emission\"].mean() if previous_data is not None else 0\n",
    "        emissions_diff = previous_emissions - current_emissions\n",
    "        reward_components[\"emissions_diff\"] = emissions_diff\n",
    "        \n",
    "        # Calculate queue length difference (using vehicle count as proxy)\n",
    "        current_queue = current_data.groupby(\"Lane_Group\")[\"Vehicle_ID\"].count().sum()\n",
    "        previous_queue = previous_data.groupby(\"Lane_Group\")[\"Vehicle_ID\"].count().sum() if previous_data is not None else 0\n",
    "        queue_diff = previous_queue - current_queue\n",
    "        reward_components[\"queue_diff\"] = queue_diff\n",
    "        \n",
    "        # Apply penalties for signal changes to discourage frequent switching\n",
    "        signal_change_penalty = -5 if action_taken > 0 else 0\n",
    "        reward_components[\"signal_change_penalty\"] = signal_change_penalty\n",
    "        \n",
    "        # Combine rewards with appropriate weights\n",
    "        reward = (\n",
    "            2.0 * waiting_diff +    # Prioritize waiting time reduction\n",
    "            1.0 * speed_diff +      # Reward speed improvements\n",
    "            0.5 * emissions_diff +  # Minor reward for emissions reduction\n",
    "            1.5 * queue_diff +      # Reward queue length reduction\n",
    "            signal_change_penalty   # Penalty for changing signals\n",
    "        )\n",
    "        \n",
    "        reward_components[\"total_reward\"] = reward\n",
    "        \n",
    "        # Log reward components\n",
    "        with open(f\"logs/reward_log_{time.time()}.json\", \"w\") as f:\n",
    "            json.dump(reward_components, f)\n",
    "        \n",
    "        return reward\n",
    "    except Exception as e:\n",
    "        print(f\"Error in calculate_reward: {e}\")\n",
    "        return 0  # Default to neutral reward on error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_progress(rewards, waiting_times, emissions, episode):\n",
    "    \"\"\"Plot and save training progress\"\"\"\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Plot rewards\n",
    "    plt.subplot(3, 1, 1)\n",
    "    plt.plot(rewards, 'b-')\n",
    "    plt.title(f'Rewards (Episode {episode})')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Total Reward')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot waiting times\n",
    "    plt.subplot(3, 1, 2)\n",
    "    plt.plot(waiting_times, 'r-')\n",
    "    plt.title('Average Waiting Time')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Waiting Time (s)')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot emissions\n",
    "    plt.subplot(3, 1, 3)\n",
    "    plt.plot(emissions, 'g-')\n",
    "    plt.title('Average CO2 Emissions')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('CO2 (g)')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'results/training_progress_ep{episode}.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_agent_segment(agent, num_episodes, max_steps_per_episode, sumocfg_path, \n",
    "                combined_data, start_episode=0, end_episode=None, \n",
    "                checkpoint_interval=5, resume_from=None):\n",
    "    \"\"\"Train the DQN agent with checkpointing for a specific segment of episodes\"\"\"\n",
    "    \n",
    "    if end_episode is None:\n",
    "        end_episode = start_episode + num_episodes\n",
    "    \n",
    "    print(f\"Training segment from episode {start_episode} to {end_episode}\")\n",
    "    rewards_history = []\n",
    "    waiting_time_history = []\n",
    "    emissions_history = []\n",
    "    \n",
    "    # Create segment-specific log directory\n",
    "    segment_log_dir = f\"logs/segment_{start_episode}_{end_episode}\"\n",
    "    os.makedirs(segment_log_dir, exist_ok=True)\n",
    "    \n",
    "    # Log file for this segment\n",
    "    log_file = open(f\"{segment_log_dir}/training_log.txt\", \"w\")\n",
    "    log_file.write(f\"Training segment from episode {start_episode} to {end_episode}\\n\")\n",
    "    log_file.write(f\"Started at: {datetime.datetime.now()}\\n\\n\")\n",
    "    \n",
    "    # Resume from checkpoint if specified\n",
    "    if resume_from is not None:\n",
    "        if agent.load(resume_from):\n",
    "            print(f\"Resuming training from checkpoint at episode {resume_from}\")\n",
    "            log_file.write(f\"Resuming from checkpoint at episode {resume_from}\\n\")\n",
    "            \n",
    "            # Load previous metrics if available\n",
    "            try:\n",
    "                rewards_history = list(np.load(f\"results/reward_history_ep{resume_from}.npy\"))\n",
    "                waiting_time_history = list(np.load(f\"results/waiting_time_history_ep{resume_from}.npy\"))\n",
    "                emissions_history = list(np.load(f\"results/emissions_history_ep{resume_from}.npy\"))\n",
    "                print(\"Loaded previous metrics successfully\")\n",
    "                log_file.write(\"Loaded previous metrics successfully\\n\")\n",
    "            except Exception as e:\n",
    "                print(f\"Could not load previous metrics: {e}\")\n",
    "                log_file.write(f\"Could not load previous metrics: {e}\\n\")\n",
    "    \n",
    "    try:\n",
    "        for episode in range(start_episode, end_episode):\n",
    "            episode_start_time = time.time()\n",
    "            print(f\"Starting episode {episode+1}/{end_episode}\")\n",
    "            log_file.write(f\"\\nEpisode {episode+1}/{end_episode}\\n\")\n",
    "            \n",
    "            # Connect to SUMO\n",
    "            try:\n",
    "                init_sumo(sumocfg_path)\n",
    "                log_file.write(\"SUMO initialized successfully\\n\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error initializing SUMO: {e}\")\n",
    "                log_file.write(f\"Error initializing SUMO: {e}\\n\")\n",
    "                continue\n",
    "            \n",
    "            # Get traffic light IDs\n",
    "            traffic_light_ids = traci.trafficlight.getIDList()\n",
    "            log_file.write(f\"Traffic lights: {traffic_light_ids}\\n\")\n",
    "            \n",
    "            # Initialize episode variables\n",
    "            total_reward = 0\n",
    "            previous_data = None\n",
    "            episode_losses = []\n",
    "            episode_waiting_times = []\n",
    "            episode_emissions = []\n",
    "            \n",
    "            for step in range(max_steps_per_episode):\n",
    "                if step % 100 == 0:\n",
    "                    print(f\"Episode {episode+1}, Step {step}/{max_steps_per_episode}\")\n",
    "                \n",
    "                # Get current timestep\n",
    "                current_timestep = step\n",
    "                \n",
    "                # Get current state\n",
    "                current_data = combined_data[combined_data[\"Timestep\"] == current_timestep]\n",
    "                if current_data.empty:\n",
    "                    print(f\"No data for timestep {current_timestep}, ending episode\")\n",
    "                    log_file.write(f\"No data for timestep {current_timestep}, ending episode\\n\")\n",
    "                    break\n",
    "                    \n",
    "                state = get_state(combined_data, current_timestep)\n",
    "                if state is None:\n",
    "                    print(f\"Could not get state for timestep {current_timestep}, skipping step\")\n",
    "                    log_file.write(f\"Could not get state for timestep {current_timestep}, skipping step\\n\")\n",
    "                    continue\n",
    "                \n",
    "                # Select action\n",
    "                action = agent.select_action(state)\n",
    "                \n",
    "                # Take action in environment\n",
    "                action_success = take_action(action, traffic_light_ids)\n",
    "                if not action_success:\n",
    "                    print(\"Action failed, skipping step\")\n",
    "                    log_file.write(\"Action failed, skipping step\\n\")\n",
    "                    continue\n",
    "                \n",
    "                # Advance simulation by one step\n",
    "                traci.simulationStep()\n",
    "                \n",
    "                # Get next state\n",
    "                next_timestep = current_timestep + 1\n",
    "                next_data = combined_data[combined_data[\"Timestep\"] == next_timestep]\n",
    "                \n",
    "                if next_data.empty:\n",
    "                    done = True\n",
    "                    print(f\"Episode ended at step {step} (no more data)\")\n",
    "                    log_file.write(f\"Episode ended at step {step} (no more data)\\n\")\n",
    "                else:\n",
    "                    done = False\n",
    "                    next_state = get_state(combined_data, next_timestep)\n",
    "                    if next_state is None:\n",
    "                        print(f\"Could not get next state for timestep {next_timestep}, ending step\")\n",
    "                        log_file.write(f\"Could not get next state for timestep {next_timestep}, ending step\\n\")\n",
    "                        continue\n",
    "                \n",
    "                # Calculate reward\n",
    "                reward = calculate_reward(current_data, previous_data, action)\n",
    "                total_reward += reward\n",
    "                \n",
    "                # Record metrics for this step\n",
    "                current_waiting_time = current_data[\"Waiting_Time\"].mean()\n",
    "                current_emissions = current_data[\"CO2_Emission\"].mean()\n",
    "                episode_waiting_times.append(current_waiting_time)\n",
    "                episode_emissions.append(current_emissions)\n",
    "                \n",
    "                if not done:\n",
    "                    # Store experience\n",
    "                    agent.store_experience(state, action, reward, next_state, done)\n",
    "                    \n",
    "                    # Train agent\n",
    "                    loss = agent.train()\n",
    "                    episode_losses.append(loss)\n",
    "                    \n",
    "                    # Update previous data\n",
    "                    previous_data = current_data\n",
    "                else:\n",
    "                    break\n",
    "            \n",
    "            # Close SUMO connection\n",
    "            traci.close()\n",
    "            \n",
    "            # Calculate episode metrics\n",
    "            episode_duration = time.time() - episode_start_time\n",
    "            avg_waiting_time = np.mean(episode_waiting_times) if episode_waiting_times else 0\n",
    "            avg_emissions = np.mean(episode_emissions) if episode_emissions else 0\n",
    "            avg_loss = np.mean(episode_losses) if episode_losses else 0\n",
    "            \n",
    "            # Record metrics\n",
    "            rewards_history.append(total_reward)\n",
    "            waiting_time_history.append(avg_waiting_time)\n",
    "            emissions_history.append(avg_emissions)\n",
    "            \n",
    "            # Update target network every episode\n",
    "            agent.update_target_network()\n",
    "            \n",
    "            # Save checkpoint at specified intervals\n",
    "            if episode % checkpoint_interval == 0 or episode == end_episode - 1:\n",
    "                agent.save(episode)\n",
    "                \n",
    "                # Save metrics\n",
    "                np.save(f\"results/reward_history_ep{episode}.npy\", np.array(rewards_history))\n",
    "                np.save(f\"results/waiting_time_history_ep{episode}.npy\", np.array(waiting_time_history))\n",
    "                np.save(f\"results/emissions_history_ep{episode}.npy\", np.array(emissions_history))\n",
    "                \n",
    "                # Plot and save current progress\n",
    "                plot_training_progress(rewards_history, waiting_time_history, emissions_history, episode)\n",
    "                \n",
    "                print(f\"Checkpoint saved at episode {episode}\")\n",
    "                log_file.write(f\"Checkpoint saved at episode {episode}\\n\")\n",
    "            \n",
    "            # Print episode summary\n",
    "            print(f\"Episode {episode+1}/{end_episode}, Duration: {episode_duration:.2f}s, \"\n",
    "                  f\"Total Reward: {total_reward:.2f}, Avg Waiting Time: {avg_waiting_time:.2f}s, \"\n",
    "                  f\"Avg Emissions: {avg_emissions:.2f}g, Avg Loss: {avg_loss:.4f}, \"\n",
    "                  f\"Epsilon: {agent.epsilon:.4f}\")\n",
    "            \n",
    "            log_file.write(f\"Episode Duration: {episode_duration:.2f}s\\n\")\n",
    "            log_file.write(f\"Total Reward: {total_reward:.2f}\\n\")\n",
    "            log_file.write(f\"Avg Waiting Time: {avg_waiting_time:.2f}s\\n\")\n",
    "            log_file.write(f\"Avg Emissions: {avg_emissions:.2f}g\\n\")\n",
    "            log_file.write(f\"Avg Loss: {avg_loss:.4f}\\n\")\n",
    "            log_file.write(f\"Epsilon: {agent.epsilon:.4f}\\n\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Training interrupted: {e}\")\n",
    "        log_file.write(f\"Training interrupted: {e}\\n\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        log_file.write(traceback.format_exc())\n",
    "    \n",
    "    finally:\n",
    "        # Close log file\n",
    "        log_file.write(f\"\\nSegment completed at: {datetime.datetime.now()}\\n\")\n",
    "        log_file.close()\n",
    "        \n",
    "        # Make sure SUMO is closed\n",
    "        try:\n",
    "            traci.close()\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return rewards_history, waiting_time_history, emissions_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_agent_segment(agent, sumocfg_path, combined_data, num_evaluation_runs=5):\n",
    "    \"\"\"Evaluate the trained agent\"\"\"\n",
    "    print(\"Starting evaluation...\")\n",
    "    \n",
    "    # Create evaluation log directory\n",
    "    eval_log_dir = \"logs/evaluation\"\n",
    "    os.makedirs(eval_log_dir, exist_ok=True)\n",
    "    \n",
    "    # Log file for evaluation\n",
    "    log_file = open(f\"{eval_log_dir}/evaluation_log.txt\", \"w\")\n",
    "    log_file.write(f\"Evaluation started at: {datetime.datetime.now()}\\n\")\n",
    "    log_file.write(f\"Number of evaluation runs: {num_evaluation_runs}\\n\\n\")\n",
    "    \n",
    "    waiting_times = []\n",
    "    emissions = []\n",
    "    rewards = []\n",
    "    \n",
    "    try:\n",
    "        for run in range(num_evaluation_runs):\n",
    "            print(f\"Evaluation run {run+1}/{num_evaluation_runs}\")\n",
    "            log_file.write(f\"\\nEvaluation run {run+1}/{num_evaluation_runs}\\n\")\n",
    "            \n",
    "            # Connect to SUMO\n",
    "            try:\n",
    "                init_sumo(sumocfg_path)\n",
    "                log_file.write(\"SUMO initialized successfully\\n\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error initializing SUMO: {e}\")\n",
    "                log_file.write(f\"Error initializing SUMO: {e}\\n\")\n",
    "                continue\n",
    "            \n",
    "            # Get traffic light IDs\n",
    "            traffic_light_ids = traci.trafficlight.getIDList()\n",
    "            \n",
    "            # Initialize run variables\n",
    "            total_reward = 0\n",
    "            previous_data = None\n",
    "            run_waiting_times = []\n",
    "            run_emissions = []\n",
    "            \n",
    "            # Run simulation with trained agent\n",
    "            for step in range(3700):  # Use the same number of steps as in your EDA\n",
    "                if step % 100 == 0:\n",
    "                    print(f\"Evaluation run {run+1}, Step {step}/3700\")\n",
    "                \n",
    "                current_timestep = step\n",
    "                \n",
    "                # Get current state\n",
    "                current_data = combined_data[combined_data[\"Timestep\"] == current_timestep]\n",
    "                if current_data.empty:\n",
    "                    print(f\"No data for timestep {current_timestep}, ending run\")\n",
    "                    log_file.write(f\"No data for timestep {current_timestep}, ending run\\n\")\n",
    "                    break\n",
    "                    \n",
    "                state = get_state(combined_data, current_timestep)\n",
    "                if state is None:\n",
    "                    print(f\"Could not get state for timestep {current_timestep}, skipping step\")\n",
    "                    log_file.write(f\"Could not get state for timestep {current_timestep}, skipping step\\n\")\n",
    "                    continue\n",
    "                \n",
    "                # Select action (no exploration during evaluation)\n",
    "                with torch.no_grad():\n",
    "                    state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "                    q_values = agent.q_network(state_tensor)\n",
    "                    action = q_values.argmax().item()\n",
    "                \n",
    "                # Take action in environment\n",
    "                action_success = take_action(action, traffic_light_ids)\n",
    "                if not action_success:\n",
    "                    print(\"Action failed, skipping step\")\n",
    "                    log_file.write(\"Action failed, skipping step\\n\")\n",
    "                    continue\n",
    "                \n",
    "                # Advance simulation\n",
    "                traci.simulationStep()\n",
    "                \n",
    "                # Calculate reward (for logging purposes)\n",
    "                reward = calculate_reward(current_data, previous_data, action)\n",
    "                total_reward += reward\n",
    "                \n",
    "                # Record metrics\n",
    "                current_waiting_time = current_data[\"Waiting_Time\"].mean()\n",
    "                current_emissions = current_data[\"CO2_Emission\"].mean()\n",
    "                run_waiting_times.append(current_waiting_time)\n",
    "                run_emissions.append(current_emissions)\n",
    "                \n",
    "                # Update previous data\n",
    "                previous_data = current_data\n",
    "            \n",
    "            # Close SUMO connection\n",
    "            traci.close()\n",
    "            \n",
    "            # Calculate run metrics\n",
    "            avg_waiting_time = np.mean(run_waiting_times) if run_waiting_times else 0\n",
    "            avg_emissions = np.mean(run_emissions) if run_emissions else 0\n",
    "            \n",
    "            # Collect metrics\n",
    "            waiting_times.append(avg_waiting_time)\n",
    "            emissions.append(avg_emissions)\n",
    "            rewards.append(total_reward)\n",
    "            \n",
    "            # Log run results\n",
    "            log_file.write(f\"Total Reward: {total_reward:.2f}\\n\")\n",
    "            log_file.write(f\"Average Waiting Time: {avg_waiting_time:.2f}s\\n\")\n",
    "            log_file.write(f\"Average CO2 Emissions: {avg_emissions:.2f}g\\n\")\n",
    "        \n",
    "        # Calculate overall metrics\n",
    "        avg_waiting_time = np.mean(waiting_times)\n",
    "        avg_emissions = np.mean(emissions)\n",
    "        avg_reward = np.mean(rewards)\n",
    "        \n",
    "        # Log overall results\n",
    "        log_file.write(f\"\\nOverall Results:\\n\")\n",
    "        log_file.write(f\"Average Reward: {avg_reward:.2f}\\n\")\n",
    "        log_file.write(f\"Average Waiting Time: {avg_waiting_time:.2f}s\\n\")\n",
    "        log_file.write(f\"Average CO2 Emissions: {avg_emissions:.2f}g\\n\")\n",
    "        \n",
    "        print(f\"Evaluation Results:\")\n",
    "        print(f\"Average Reward: {avg_reward:.2f}\")\n",
    "        print(f\"Average Waiting Time: {avg_waiting_time:.2f}s\")\n",
    "        print(f\"Average CO2 Emissions: {avg_emissions:.2f}g\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Evaluation interrupted: {e}\")\n",
    "        log_file.write(f\"Evaluation interrupted: {e}\\n\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        log_file.write(traceback.format_exc())\n",
    "    \n",
    "    finally:\n",
    "        # Close log file\n",
    "        log_file.write(f\"\\nEvaluation completed at: {datetime.datetime.now()}\\n\")\n",
    "        log_file.close()\n",
    "        \n",
    "        # Make sure SUMO is closed\n",
    "        try:\n",
    "            traci.close()\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return avg_waiting_time, avg_emissions, avg_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_segment_results(segment, rewards, waiting_times, emissions):\n",
    "    \"\"\"Plot and save results for a training segment\"\"\"\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    \n",
    "    # Plot rewards\n",
    "    plt.subplot(3, 1, 1)\n",
    "    plt.plot(rewards, 'b-')\n",
    "    plt.title(f'Rewards (Segment {segment})')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Total Reward')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot waiting times\n",
    "    plt.subplot(3, 1, 2)\n",
    "    plt.plot(waiting_times, 'r-')\n",
    "    plt.title('Average Waiting Time')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Waiting Time (s)')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot emissions\n",
    "    plt.subplot(3, 1, 3)\n",
    "    plt.plot(emissions, 'g-')\n",
    "    plt.title('Average CO2 Emissions')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('CO2 (g)')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'results/segment_{segment}_results.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_segmented():\n",
    "    \"\"\"Main function with segmented training to allow for recovery\"\"\"\n",
    "    print(\"Starting traffic light optimization with RL...\")\n",
    "    \n",
    "    # Create necessary directories\n",
    "    os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "    os.makedirs(\"results\", exist_ok=True)\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    os.makedirs(\"logs\", exist_ok=True)\n",
    "    \n",
    "    # Load data\n",
    "    combined_data = load_data()\n",
    "    if combined_data is None:\n",
    "        print(\"Failed to load data. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    # Save configuration\n",
    "    config = {\n",
    "        \"sumocfg_path\": \"C:/Users/Pushp Raj Choudhary/2025-03-14-16-24-53/osm.sumocfg\",\n",
    "        \"total_episodes\": 100,\n",
    "        \"episodes_per_segment\": 10,\n",
    "        \"max_steps_per_episode\": 3700,\n",
    "        \"checkpoint_interval\": 2,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"gamma\": 0.95,\n",
    "        \"epsilon_start\": 1.0,\n",
    "        \"epsilon_decay\": 0.995,\n",
    "        \"epsilon_min\": 0.01,\n",
    "        \"buffer_size\": 10000,\n",
    "        \"batch_size\": 32,\n",
    "        \"evaluation_runs\": 5\n",
    "    }\n",
    "    \n",
    "    with open(\"config.json\", \"w\") as f:\n",
    "        json.dump(config, f, indent=4)\n",
    "    \n",
    "    # Define state and action sizes\n",
    "    # Adjust state_size based on your actual state representation\n",
    "    state_size = 50  # This should match the length of your state vector\n",
    "    action_size = 4  # Do nothing, Switch phase, Extend phase, Reduce phase\n",
    "    \n",
    "    # Create agent\n",
    "    agent = DQNAgent(\n",
    "        state_size=state_size,\n",
    "        action_size=action_size,\n",
    "        learning_rate=config[\"learning_rate\"],\n",
    "        gamma=config[\"gamma\"],\n",
    "        epsilon=config[\"epsilon_start\"],\n",
    "        epsilon_decay=config[\"epsilon_decay\"],\n",
    "        epsilon_min=config[\"epsilon_min\"],\n",
    "        buffer_size=config[\"buffer_size\"],\n",
    "        batch_size=config[\"batch_size\"]\n",
    "    )\n",
    "    \n",
    "    # Training parameters\n",
    "    total_episodes = config[\"total_episodes\"]\n",
    "    episodes_per_segment = config[\"episodes_per_segment\"]\n",
    "    max_steps_per_episode = config[\"max_steps_per_episode\"]\n",
    "    sumocfg_path = config[\"sumocfg_path\"]\n",
    "    checkpoint_interval = config[\"checkpoint_interval\"]\n",
    "    \n",
    "    # Check for resume flag\n",
    "    resume_from = None\n",
    "    resume_segment = 0\n",
    "    \n",
    "    # Check if there are existing checkpoints\n",
    "    checkpoints = [f for f in os.listdir(\"checkpoints\") if f.startswith(\"agent_checkpoint_ep\")]\n",
    "    if checkpoints:\n",
    "        # Extract episode numbers from checkpoint filenames\n",
    "        checkpoint_episodes = [int(f.split(\"ep\")[1].split(\".\")[0]) for f in checkpoints]\n",
    "        if checkpoint_episodes:\n",
    "            latest_checkpoint = max(checkpoint_episodes)\n",
    "            print(f\"Found latest checkpoint at episode {latest_checkpoint}\")\n",
    "            resume_option = input(f\"Resume from episode {latest_checkpoint}? (y/n): \")\n",
    "            if resume_option.lower() == 'y':\n",
    "                resume_from = latest_checkpoint\n",
    "                resume_segment = resume_from // episodes_per_segment\n",
    "                print(f\"Resuming from segment {resume_segment}\")\n",
    "    \n",
    "    # Train in segments\n",
    "    try:\n",
    "        for segment in range(resume_segment, total_episodes // episodes_per_segment):\n",
    "            start_episode = segment * episodes_per_segment\n",
    "            end_episode = min((segment + 1) * episodes_per_segment, total_episodes)\n",
    "            \n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"Starting training segment {segment+1}/{total_episodes // episodes_per_segment}\")\n",
    "            print(f\"Episodes {start_episode} to {end_episode-1}\")\n",
    "            print(f\"{'='*50}\\n\")\n",
    "            \n",
    "            # Train for this segment\n",
    "            rewards, waiting_times, emissions = train_agent_segment(\n",
    "                agent=agent,\n",
    "                num_episodes=episodes_per_segment,\n",
    "                max_steps_per_episode=max_steps_per_episode,\n",
    "                sumocfg_path=sumocfg_path,\n",
    "                combined_data=combined_data,\n",
    "                start_episode=start_episode,\n",
    "                end_episode=end_episode,\n",
    "                checkpoint_interval=checkpoint_interval,\n",
    "                resume_from=resume_from if segment == resume_segment else None\n",
    "            )\n",
    "            \n",
    "            # Only use resume_from for the first segment after resuming\n",
    "            resume_from = None\n",
    "            \n",
    "            # Save segment results\n",
    "            np.save(f\"results/segment_{segment}_rewards.npy\", np.array(rewards))\n",
    "            np.save(f\"results/segment_{segment}_waiting_times.npy\", np.array(waiting_times))\n",
    "            np.save(f\"results/segment_{segment}_emissions.npy\", np.array(emissions))\n",
    "            \n",
    "            # Plot segment results\n",
    "            plot_segment_results(segment, rewards, waiting_times, emissions)\n",
    "            \n",
    "            # Save model after each segment\n",
    "            torch.save(agent.q_network.state_dict(), f\"models/q_network_segment_{segment}.pth\")\n",
    "            \n",
    "            # Evaluate after each segment\n",
    "            print(\"\\nEvaluating agent after segment completion...\")\n",
    "            avg_waiting, avg_emissions, avg_reward = evaluate_agent_segment(\n",
    "                agent=agent,\n",
    "                sumocfg_path=sumocfg_path,\n",
    "                combined_data=combined_data,\n",
    "                num_evaluation_runs=config[\"evaluation_runs\"]\n",
    "            )\n",
    "            \n",
    "            # Save evaluation results\n",
    "            with open(f\"results/segment_{segment}_evaluation.json\", \"w\") as f:\n",
    "                json.dump({\n",
    "                    \"avg_waiting_time\": avg_waiting,\n",
    "                    \"avg_emissions\": avg_emissions,\n",
    "                    \"avg_reward\": avg_reward\n",
    "                }, f, indent=4)\n",
    "            \n",
    "            # Ask if user wants to continue to next segment\n",
    "            if segment < (total_episodes // episodes_per_segment) - 1:\n",
    "                continue_option = input(f\"Continue to segment {segment+2}? (y/n): \")\n",
    "                if continue_option.lower() != 'y':\n",
    "                    print(\"Training paused. You can resume later from the latest checkpoint.\")\n",
    "                    break\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nTraining interrupted by user.\")\n",
    "        print(\"You can resume later from the latest checkpoint.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError during training: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        print(\"You can resume later from the latest checkpoint.\")\n",
    "    \n",
    "    finally:\n",
    "        # Final evaluation after all segments\n",
    "        print(\"\\nPerforming final evaluation...\")\n",
    "        final_waiting, final_emissions, final_reward = evaluate_agent_segment(\n",
    "            agent=agent,\n",
    "            sumocfg_path=sumocfg_path,\n",
    "            combined_data=combined_data,\n",
    "            num_evaluation_runs=config[\"evaluation_runs\"] * 2  # More runs for final evaluation\n",
    "        )\n",
    "        \n",
    "        # Save final model\n",
    "        torch.save(agent.q_network.state_dict(), \"models/q_network_final.pth\")\n",
    "        \n",
    "        # Save final evaluation results\n",
    "        with open(\"results/final_evaluation.json\", \"w\") as f:\n",
    "            json.dump({\n",
    "                \"avg_waiting_time\": final_waiting,\n",
    "                \"avg_emissions\": final_emissions,\n",
    "                \"avg_reward\": final_reward\n",
    "            }, f, indent=4)\n",
    "        \n",
    "        print(\"\\nTraining completed!\")\n",
    "        print(f\"Final model saved to models/q_network_final.pth\")\n",
    "        print(f\"Final evaluation results: Avg Waiting Time: {final_waiting:.2f}s, Avg Emissions: {final_emissions:.2f}g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[55]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPyTorch version: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch.__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# Run the main function\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m \u001b[43mmain_segmented\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# Close log file\u001b[39;00m\n\u001b[32m     38\u001b[39m log_file.close()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 155\u001b[39m, in \u001b[36mmain_segmented\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    153\u001b[39m     \u001b[38;5;66;03m# Final evaluation after all segments\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mPerforming final evaluation...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m     final_waiting, final_emissions, final_reward = \u001b[43mevaluate_agent_segment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m        \u001b[49m\u001b[43magent\u001b[49m\u001b[43m=\u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m        \u001b[49m\u001b[43msumocfg_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43msumocfg_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcombined_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcombined_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_evaluation_runs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mevaluation_runs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# More runs for final evaluation\u001b[39;49;00m\n\u001b[32m    160\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# Save final model\u001b[39;00m\n\u001b[32m    163\u001b[39m     torch.save(agent.q_network.state_dict(), \u001b[33m\"\u001b[39m\u001b[33mmodels/q_network_final.pth\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 49\u001b[39m, in \u001b[36mevaluate_agent_segment\u001b[39m\u001b[34m(agent, sumocfg_path, combined_data, num_evaluation_runs)\u001b[39m\n\u001b[32m     46\u001b[39m current_timestep = step\n\u001b[32m     48\u001b[39m \u001b[38;5;66;03m# Get current state\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m current_data = \u001b[43mcombined_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcombined_data\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTimestep\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_timestep\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m current_data.empty:\n\u001b[32m     51\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo data for timestep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_timestep\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, ending run\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Pushp Raj Choudhary\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:4093\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4091\u001b[39m \u001b[38;5;66;03m# Do we have a (boolean) 1d indexer?\u001b[39;00m\n\u001b[32m   4092\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m com.is_bool_indexer(key):\n\u001b[32m-> \u001b[39m\u001b[32m4093\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem_bool_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4095\u001b[39m \u001b[38;5;66;03m# We are left with two options: a single key, and a collection of keys,\u001b[39;00m\n\u001b[32m   4096\u001b[39m \u001b[38;5;66;03m# We interpret tuples as collections only for non-MultiIndex\u001b[39;00m\n\u001b[32m   4097\u001b[39m is_single_key = \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(key)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Pushp Raj Choudhary\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:4151\u001b[39m, in \u001b[36mDataFrame._getitem_bool_array\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4147\u001b[39m \u001b[38;5;66;03m# check_bool_indexer will throw exception if Series key cannot\u001b[39;00m\n\u001b[32m   4148\u001b[39m \u001b[38;5;66;03m# be reindexed to match DataFrame rows\u001b[39;00m\n\u001b[32m   4149\u001b[39m key = check_bool_indexer(\u001b[38;5;28mself\u001b[39m.index, key)\n\u001b[32m-> \u001b[39m\u001b[32m4151\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mkey\u001b[49m\u001b[43m.\u001b[49m\u001b[43mall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   4152\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.copy(deep=\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m   4154\u001b[39m indexer = key.nonzero()[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Pushp Raj Choudhary\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\_methods.py:73\u001b[39m, in \u001b[36m_all\u001b[39m\u001b[34m(a, axis, dtype, out, keepdims, where)\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;66;03m# Parsing keyword arguments is currently fairly slow, so avoid it for now\u001b[39;00m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m where \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m umr_all(a, axis, dtype, out, keepdims, where=where)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Set random seeds for reproducibility\n",
    "    random.seed(42)\n",
    "    np.random.seed(42)\n",
    "    torch.manual_seed(42)\n",
    "    \n",
    "    # Add current date and time to log files\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    os.makedirs(f\"logs/{current_time}\", exist_ok=True)\n",
    "    \n",
    "    # Redirect stdout to both console and log file\n",
    "    log_file = open(f\"logs/{current_time}/main_log.txt\", \"w\")\n",
    "    \n",
    "    class Logger:\n",
    "        def __init__(self, console, file):\n",
    "            self.console = console\n",
    "            self.file = file\n",
    "            \n",
    "        def write(self, message):\n",
    "            self.console.write(message)\n",
    "            self.file.write(message)\n",
    "            \n",
    "        def flush(self):\n",
    "            self.console.flush()\n",
    "            self.file.flush()\n",
    "    \n",
    "    sys.stdout = Logger(sys.stdout, log_file)\n",
    "    \n",
    "    # Print start time\n",
    "    print(f\"Starting at: {current_time}\")\n",
    "    print(f\"Python version: {sys.version}\")\n",
    "    print(f\"PyTorch version: {torch.__version__}\")\n",
    "    \n",
    "    # Run the main function\n",
    "    main_segmented()\n",
    "    \n",
    "    # Close log file\n",
    "    log_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
